% Encoding: UTF-8

@article{Haykin2001 ,
abstract = {As redes neurais artificiais t{\^{e}}m ra{\'{i}}zes em disciplinas como neuroci{\^{e}}ncia, matem{\'{a}}tica, estat{\'{i}}stica, f{\'{i}}sica, ci{\^{e}}ncia da computa{\c{c}}{\~{a}}o e engenharia. Suas aplica{\c{c}}{\~{o}}es podem ser encontradas em campos t{\~{a}}o diversos quanto modelagem, an{\'{a}}lise de s{\'{e}}ries temporais, reconhecimento de padr{\~{o}}es, processamento de sinais e controle. Este livro fornece as bases para o entendimento das redes neurais, reconhecendo a natureza multidisciplinar do tema.},
author = {Haykin, Simon},
pages = {901},
title = {{Redes Neurais - Princ{\'{i}}pios e pr{\'{a}}tica}},
volume = {2},
year = {2001}
}

@article{Cintra2019,
author = {Cintra, Rosangela},
file = {:home/felipe/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cintra - Unknown - Introdu{\c{c}}{\~{a}}o {\`{a}} Neurcomputa{\c{c}}{\~{a}}o.pdf:pdf},
journal = {ELAC 2019},
keywords = {especialistas},
pages = {22},
title = {{Introdu{\c{c}}{\~{a}}o {\`{a}} Neurocomputa{\c{c}}{\~{a}}o}},
year = {2019}
}

@article{Nelson2017,
abstract = {Predictions on stock market prices are a great challenge due to the fact that it is an immensely complex, chaotic and dynamic environment. There are many studies from various areas aiming to take on that challenge and Machine Learning approaches have been the focus of many of them. There are many examples of Machine Learning algorithms being able to reach satisfactory results when doing that type of prediction. This project studies the usage of LSTM networks on that scenario, to predict future trends of stock prices based on the price history, alongside with technical analysis indicators. For that goal, a prediction model was built, and a series of experiments were executed and theirs results analyzed against a number of metrics to assess if this type of algorithm presents any improvements when compared to other Machine Learning methods and investment strategies. The results that were obtained are promising, getting up to an average of 55.9{\%} of accuracy when predicting if the price of a particular stock is going to go up or not in the near future. This model was also assessed under financial aspects, showing promissing results in terms of financial returns.},
author = {Nelson, David Michael Quirino},
keywords = {Artificial Neural Networks,Deep Learning,Long Short-Term Memory,Machine Learning,Recurrent Neural Networks,Stock Markets,Technical Analysis},
pages = {55},
title = {{Uso de redes neurais recorrentes para previs{\~{a}}o de s{\'{e}}ries temporais financeiras}},
year = {2017}
}

@article{Osorio1999,
abstract = {Forum de I.A. '99 – Pg.1 Introdu{\c{c}}{\~{a}}o Este tutorial tem por objetivo apresentar uma introdu{\c{c}}{\~{a}}o ao aprendizado artificial e automatizado (machine learning), focalizando-se sobre os aspectos referentes a uma t{\'{e}}cnica em particular, as redes neurais artificiais –R.N.A. Na primeira se{\c{c}}{\~{a}}o vamos discutir sobre a Intelig{\^{e}}ncia Artificial, sobre a aquisi{\c{c}}{\~{a}}o de conhecimentos e sobre a import{\^{a}}ncia do aprendizado na constru{\c{c}}{\~{a}}o de sistemas inteligentes. Na segunda se{\c{c}}{\~{a}}o iremos abordar as redes neurais artificiais (modelos conexionistas), onde vamos destacar: os diferentes tipos de redes e de algoritmos de aprendizado existentes; a representa{\c{c}}{\~{a}}o do conhecimento neural; as caracter{\'{i}}sticas e limita{\c{c}}{\~{o}}es de uso deste tipo de t{\'{e}}cnicas, bem como mostraremos alguns exemplos de aplica{\c{c}}{\~{o}}es das RNAs. Para concluir, iremos discutir sobre os caminhos da pesquisa atual nesta {\'{a}}rea e tend{\^{e}}ncias futuras no que diz respeito ao desenvolvimento dos sistemas inteligentes.},
author = {Os{\'{o}}rio, Fernando},
journal = {I Forum De Intelig{\^{e}}ncia Artificial},
number = {1},
pages = {1--32},
title = {{Redes Neurais - Aprendizado Artificial}},
url = {http://osorio.wait4.org/oldsite/IForumIA/fia99.pdf},
year = {1999}
}

@BOOK {livroNunes2016,
    author    = "Silva, Ivan Nunes da and Spatti, Danilo Hernane and Flauzino, Rogério Andrade",
    title     = "Redes Neurais Artificiais Para Engenharia e Ciências Aplicadas. Fundamentos Teóricos e Aspectos Práticos",
    publisher = "Artliber",
    year      = "2016",
    edition   = "second",
    month     = "dec"
}

@inbook{bezerra2016,
author = {Bezerra, Eduardo},
file = {:home/felipe/Documentos/livros/sbbd2016-intro-deep-learning.pdf:pdf},
pages = {57--86},
title = {{Introdu{\c{c}}{\~{a}}o {\`{a}} Aprendizagem Profunda}},
year = {2016}
}

@article{Camila2017,
author = {da Silva, Larrisa Camila Ferreira},
file = {:home/felipe/Documentos/livros/lcfs{\_}tg.pdf:pdf},
title = {{Modelo de Transfer{\^{e}}ncia de Aprendizagem baseado em Regress{\~{a}}o Linear Regularizada}},
year = {2017}
}

@book{Ponti2018,
abstract = {Deep Learning methods are currently the state-of-the-art in many problems which can be tackled via machine learning, in particular classification problems. However there is still lack of understanding on how those methods work, why they work and what are the limitations involved in using them. In this chapter we will describe in detail the transition from shallow to deep networks, include examples of code on how to implement them, as well as the main issues one faces when training a deep network. Afterwards, we introduce some theoretical background behind the use of deep models, and discuss their limitations.},
archivePrefix = {arXiv},
arxivId = {1806.07908},
author = {Ponti, Moacir Antonelli and da Costa, Gabriel B. Paranhos},
eprint = {1806.07908},
file = {:home/felipe/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponti, da Costa - 2018 - Como funciona o Deep Learning.pdf:pdf},
isbn = {9788576694007},
pages = {63--93},
title = {{Como funciona o Deep Learning}},
url = {http://arxiv.org/abs/1806.07908},
year = {2018}
}

@article{Carneiro2017,
abstract = {Convolutional Neural Networks (CNNs) belong to a category of algorithms based on artificial neural networks that use convolution in at least one of their layers. CNNs have proven to be efficient in various tasks of image and video recognition, recommendation systems and natural language processing, however they need a large number of labeled samples for learning. Thus, in addition to introducing the main concepts and components of CNNs, this chapter also discusses how to use transfer learning techniques to accelerate CNN training process or extract features of databases that do not have sufficient images for the training. Finally, we present a tutorial in python on how to use the Tensorflow library to build and run a CNN to classify images. Resumo},
author = {Ara\'ujo, Flávio H. D and Carneiro, Allan C and Silva, Romuere R. V and Medeiros, Fátima N. S. and Ushizima, Daniela M.},
file = {:home/felipe/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carneiro, Silva - 2017 - Redes Neurais Convolucionais com Tensorflow Teoria e Pr{\'{a}}tica.pdf:pdf},
isbn = {9788576693956},
journal = {III Escola Regional de Inform{\'{a}}tica do Piau{\'{i}}},
pages = {382--406},
title = {{Redes Neurais Convolucionais com Tensorflow: Teoria e Pr{\'{a}}tica}},
year = {2017}
}

@article{decio2017,
author = {Neto, Décio Gonçalves de Aguiar},
file = {:home/felipe/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/D{\'{E}}CIO GON{\c{C}}ALVES DE AGUIAR NETO - 2017 - TRANSFER{\^{E}}NCIA DE CONHECIMENTO UTILIZANDO APRENDIZADO PROFUNDO PARA CLASSIFICA{\c{C}}{\~{A}}O DE IMAGEN.pdf:pdf},
pages = {399--404},
title = {{TRANSFER{\^{E}}NCIA DE CONHECIMENTO UTILIZANDO APRENDIZADO PROFUNDO PARA CLASSIFICA{\c{C}}{\~{A}}O DE IMAGENS HISTOPATOL{\'{O}}GICAS}},
year = {2017}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{Shankar2017,
abstract = {In this paper, we present a unified end-to-end approach to build a large scale Visual Search and Recommendation system for e-commerce. Previous works have targeted these problems in isolation. We believe a more effective and elegant solution could be obtained by tackling them together. We propose a unified Deep Convolutional Neural Network architecture, called VisNet, to learn embeddings to capture the notion of visual similarity, across several semantic granularities. We demonstrate the superiority of our approach for the task of image retrieval, by comparing against the state-of-the-art on the Exact Street2Shop dataset. We then share the design decisions and trade-offs made while deploying the model to power Visual Recommendations across a catalog of 50M products, supporting 2K queries a second at Flipkart, India's largest e-commerce company. The deployment of our solution has yielded a significant business impact, as measured by the conversion-rate.},
archivePrefix = {arXiv},
arxivId = {1703.02344},
author = {Shankar, Devashish and Narumanchi, Sujay and Ananya, H A and Kompalli, Pramod and Chaudhury, Krishnendu},
doi = {10.1029/2001JD000377},
eprint = {1703.02344},
file = {:home/felipe/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shankar et al. - 2017 - Deep Learning based Large Scale Visual Recommendation and Search for E-Commerce.pdf:pdf},
issn = {0148-0227},
keywords = {c,computer vision,deep learning,detail based similarity via,distributed systems,e-commerce,image retrieval,recommender systems,visual search},
pmid = {18663850},
title = {{Deep Learning based Large Scale Visual Recommendation and Search for E-Commerce}},
url = {http://arxiv.org/abs/1703.02344},
year = {2017}
}

@inproceedings{Krizhevsky2012,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
 series = {NIPS'12},
 year = {2012},
 location = {Lake Tahoe, Nevada},
 pages = {1097--1105},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2999134.2999257},
 acmid = {2999257},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 

@article{Caroline2016,
abstract = {Resumo—Este trabalho aborda o tema de Aprendizado Pro-fundo com um olhar d{\'{a}} area de Vis{\~{a}}o Computacional, tra{\c{c}}ando um paralelo entre as dua areas para a tarefa de detec ao de pedestres. Para tanto, os resultados de duas abordagens cl{\'{a}}ssicas de detec ao de pedestres s{\~{a}}o comparados experimentalmente com uma abordagem de Redes Neurais Convolucionais, cujos resultados s{\~{a}}o considerados o estado da arte para o problema em quest{\~{a}}o. Keywords-Detec ao de Pedestres, Vis{\~{a}}o Computacional, Apren-dizado Profundo, CNN, SVM, HOG, Adaboost, Haar features Abstract—This work addresses Deep Learning from the point of view of the Computer Vision area, drawing a parallel between the two areas, considering the pedestrian detection task. To achieve that, the experimental results of two classical Computer Vision approaches are compared to the results obtained from a Convolutional Neural Network, which is known for obtaining the state of the art to the problem of pedestrian detection.},
author = {Vargas, Ana Caroline and Paes, Aline and Vasconcelos, Cristina Nader},
file = {:home/felipe/Documentos/livros/um-estudo-sobre.pdf:pdf},
isbn = {142440357X},
keywords = {Adaboost,CNN,Computer Vision,HOG,Haar features.,Machine Learning,Pedestrian Detection,SVM},
pages = {4},
title = {{Um Estudo sobre Redes Neurais Convolucionais e sua Aplica{\c{c}}{\~{a}}o em Detec{\c{c}}{\~{a}}o de Pedestres}},
url = {http://sibgrapi.sid.inpe.br/col/sid.inpe.br/sibgrapi/2016/09.12.15.44/doc/um-estudo-sobre.pdf},
year = {2016}
}

@article{Miyazaki2017,
author = {Miyazaki, Caio Kioshi},
file = {:home/felipe/Documentos/livros/Miyazaki{\_}caio{\_}tcc.pdf:pdf},
title = {{Redes neurais convolucionais para aprendizagem e reconhecimento de objetos 3D}},
year = {2017}
}

@article{LeCun1998,
author = {LeCun, Yann and Bottou, L{\'{e}}on and Bengion, Yoshua and Haffner, Patrick},
file = {:home/felipe/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LeCun et al. - 1998 - Gradient-Based Learning Applied to Document Recognition.pdf:pdf},
title = {{Gradient-Based Learning Applied to Document Recognition}},
url = {http://ieeexplore.ieee.org/document/726791/{\#}full-text-section},
year = {1998}
}

@article{VonZuben2013,
author = "Von Zuben, Fernando J.",
file = {:home/felipe/Documentos/livros/introducao{\_}EA072{\_}2s2013.pdf:pdf},
keywords = {que pensam como},
pages = {1--48},
title = {{Introdu{\c{c}}{\~{a}}o {\`{a}} Intelig{\^{e}}ncia Artificial}},
year = {2013}
}

@BOOK{Winston1992,
    author    = "Winston, Patrick Henry",
    title     = "Artificial Intelligence",
    publisher = "Addison-Wesley",
    year      = "1992",
    volume    = "3"
}

@MISC {Augusto2007,
    author = "José Augusto Baranauskas",
    title  = "Aprendizado de Máquina Conceitos e Definições",
    year   = "2007"
}

@TECHREPORT {Amidi2018,
    author      = "Amidi, Shervine",
    title       = "Convolutional Neural Networks cheatsheet",
    institution = "Stanford",
    year        = "2018"
}

@TECHREPORT {Amidi2018Tricks,
    author       = "Amidi, Shervine",
    title        = "Deep Learning Tips and Tricks cheatsheet",
    year         = "2018"
}

@article{rawat2017,
author = {Rawat, Waseem and Wang, Zenghui},
doi = {10.1162/NECO_a_00990},
journal = {Neural Computation},
pages = {1--98},
title = {{Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review}},
volume = {29},
year = {2017}
}

@book{Bishop2006,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bishop, Christopher},
booktitle = {Journal of Organic Chemistry},
doi = {10.1021/jo01026a014},
eprint = {arXiv:1011.1669v3},
file = {:home/felipe/Documentos/livros/Bishop - Pattern Recognition And Machine Learning - Springer  2006.pdf:pdf},
isbn = {9780387310732},
issn = {0022-3263},
pmid = {25246403},
publisher = {Springer},
title = {{Pattern Recognition and Machine Learning}},
year = {2006}
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@article{george2017,
  author    = {George Papandreou and
               Tyler Zhu and
               Nori Kanazawa and
               Alexander Toshev and
               Jonathan Tompson and
               Chris Bregler and
               Kevin P. Murphy},
  title     = {Towards Accurate Multi-person Pose Estimation in the Wild},
  journal   = {CoRR},
  volume    = {abs/1701.01779},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.01779},
  archivePrefix = {arXiv},
  eprint    = {1701.01779},
  timestamp = {Mon, 13 Aug 2018 16:47:16 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/PapandreouZKTTB17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{george2018,
  author    = {George Papandreou and
               Tyler Zhu and
               Liang{-}Chieh Chen and
               Spyros Gidaris and
               Jonathan Tompson and
               Kevin Murphy},
  title     = {PersonLab: Person Pose Estimation and Instance Segmentation with a
               Bottom-Up, Part-Based, Geometric Embedding Model},
  journal   = {CoRR},
  volume    = {abs/1803.08225},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.08225},
  archivePrefix = {arXiv},
  eprint    = {1803.08225},
  timestamp = {Mon, 13 Aug 2018 16:47:18 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1803-08225},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{tensorflow2015-whitepaper,
title={{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={http://tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dan~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@INPROCEEDINGS{bergstra+al:2010-scipy,
     author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
      month = jun,
      title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
       year = {2010},
   location = {Austin, TX},
       note = {Oral Presentation},
   abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPy’s syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPy’s syntax and semantics, while being statically typed and
functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates
them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1.6× to 7.5× faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the
CPU and between 6.5× and 44× faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design.}
}

@misc{chollet2015,
author = {François Chollet },
title = {keras},
year = {2015},
publisher = {GitHub},
journal = {GitHub repository},
howpublished = {\url{https://github.com/fchollet/keras}},
commit = {5bcac37}
}

@ONLINE {colab,
    author = "Google",
    title  = "Google Colaboratory",
    url    = "https://research.google.com/colaboratory/faq.html"
}

@Article{PER-GRA:2007,
  Author    = {P\'erez, Fernando and Granger, Brian E.},
  Title     = {{IP}ython: a System for Interactive Scientific Computing},
  Journal   = {Computing in Science and Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {21--29},
  month     = may,
  year      = 2007,
  url       = "http://ipython.org",
  ISSN      = "1521-9615",
  doi       = {10.1109/MCSE.2007.53},
  publisher = {IEEE Computer Society},
}

@article{Carneiro2018,
abstract = {Google Colaboratory (also known as Colab) is a cloud service based on Jupyter Notebooks for disseminating machine learning education and research. It provides a runtime fully configured for deep learning and free-of-charge access to a robust GPU. This paper presents a detailed analysis of Colaboratory regarding hardware resources, performance, and limitations. This analysis is performed through the use of Colaboratory for accelerating deep learning for computer vision and other GPU-centric applications. The chosen test-cases are a parallel tree-based combinatorial search and two computer vision applications: object detection/classification and object localization/segmentation. The hardware under the accelerated runtime is compared with a mainstream workstation and a robust Linux server equipped with 20 physical cores. Results show that the performance reached using this cloud service is equivalent to the performance of the dedicated testbeds, given similar resources. Thus, this service can be effectively exploited to accelerate not only deep learning but also other classes of GPU-centric applications. For instance, it is faster to train a CNN on Colaboratory's accelerated runtime than using 20 physical cores of a Linux server. The performance of the GPU made available by Colaboratory may be enough for several profiles of researchers and students. However, these free-of-charge hardware resources are far from enough to solve demanding real-world problems and are not scalable. The most significant limitation found is the lack of CPU cores. Finally, several strengths and limitations of this cloud service are discussed, which might be useful for helping potential users.},
author = {Carneiro, Tiago and {Da Nobrega}, Raul Victor Medeiros and Nepomuceno, Thiago and Bian, Gui Bin and {De Albuquerque}, Victor Hugo C. and Filho, Pedro Pedrosa Reboucas},
doi = {10.1109/ACCESS.2018.2874767},
file = {:home/felipe/Documentos/livros/Performance{\_}Analysis{\_}of{\_}Google{\_}Colaboratory{\_}as{\_}a{\_}T.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Colab,Deep learning,GPU computing,Google colaboratory,convolutional neural networks},
pages = {61677--61685},
title = {{Performance Analysis of Google Colaboratory as a Tool for Accelerating Deep Learning Applications}},
volume = {6},
year = {2018}
}

@article{tensorflowjs2019,
  author    = {Daniel Smilkov and
               Nikhil Thorat and
               Yannick Assogba and
               Ann Yuan and
               Nick Kreeger and
               Ping Yu and
               Kangyi Zhang and
               Shanqing Cai and
               Eric Nielsen and
               David Soergel and
               Stan Bileschi and
               Michael Terry and
               Charles Nicholson and
               Sandeep N. Gupta and
               Sarah Sirajuddin and
               D. Sculley and
               Rajat Monga and
               Greg Corrado and
               Fernanda B. Vi{\'{e}}gas and
               Martin Wattenberg},
  title     = {TensorFlow.js: Machine Learning for the Web and Beyond},
  journal   = {CoRR},
  volume    = {abs/1901.05350},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.05350},
  archivePrefix = {arXiv},
  eprint    = {1901.05350},
  timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1901-05350},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@unknown{Remes2016,
author = {Remes, Chrystian},
doi = {10.13140/RG.2.1.3530.5849},
title = {{Caracteriza{\c{c}}{\~{a}}o Por Simula{\c{c}}{\~{a}}o Num{\'{e}}rica de Pain{\'{e}}is Fotovoltaicos e M{\'{e}}todo de Rastreamento do M{\'{a}}ximo Ponto de Pot{\^{e}}ncia Baseado em Redes Neurais Artificiais.}},
year = {2016}
}

@MISC {opencv2019,
    author       = "Heinisuo, Olli-Pekka",
    title        = "OpenCV Python",
    howpublished = "https://pypi.org/project/opencv-python/#description",
    year         = "2019"
}

@article{Magalh2018,
author = {Magalhães, Gabriel Ilharco},
file = {:home/felipe/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Magalh - 2018 - RECONHECIMENTO DE GESTOS DA L{\'{I}}NGUA BRASILEIRA DE SINAIS ATRAV{\'{E}}S DE REDES NEURAIS.pdf:pdf},
title = {{RECONHECIMENTO DE GESTOS DA L{\'{I}}NGUA BRASILEIRA DE SINAIS ATRAV{\'{E}}S DE REDES NEURAIS}},
year = {2018}
}

@article{Papoutsaki2016,
author = {Papoutsaki, Alexandra and Laskey, James},
file = {:home/felipe/Documentos/livros/Final{\_}WebGazer{\_}IJCAI16.pdf:pdf},
title = {{WebGazer : Scalable Webcam Eye Tracking Using User Interactions}},
year = {2016}
}

@ONLINE {Python2019,
    author = "Van Rossum, Guido",
    title  = "Python Programming Language",
    year   = "1995",
    url    = "https://www.python.org/"
}

@article{Russakovsky2015,
abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.},
archivePrefix = {arXiv},
arxivId = {1409.0575},
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
doi = {10.1007/s11263-015-0816-y},
eprint = {1409.0575},
file = {:home/felipe/Documentos/livros/1409.0575.pdf:pdf},
isbn = {0920-5691},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Benchmark,Dataset,Large-scale,Object detection,Object recognition},
number = {3},
pages = {211--252},
pmid = {16190471},
title = {{ImageNet Large Scale Visual Recognition Challenge}},
volume = {115},
year = {2015}
}


@ONLINE {PoseNetMedium2019,
    author = "Dan Oved",
    title  = "Real-time Human Pose Estimation in the Browser with TensorFlow.js",
    year   = "2018",
    url    = "https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5"
}

@article{McCullochS1943,
author = {{McCulloch}, Warren and {Pitts}, Walter},
file = {:home/felipe/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 1943 - A Logical Calculus of the Ideas Immanent in Nervous Activity.pdf:pdf},
title = {{A Logical Calculus of the Ideas Immanent in Nervous Activity}},
volume = {5},
year = {1943}
}

@article{Hodgkin1952,
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Hodgkin, A L and Huxley, A F},
doi = {10.1080/00062278.1939.10600645},
eprint = {NIHMS150003},
file = {:home/felipe/Documentos/livros/jphysiol01442-0106.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {09237984},
pages = {500--544},
title = {{A QUANTITATIVE DESCRIPTION OF MEMBRANE CURRENT AND ITS APPLICATION TO CONDUCTION AND EXCITATION IN NERVE}},
volume = {117},
year = {1952}
}


@ARTICLE {fmenino2019a,
    author  = "Menino, Felipe Carlos and  Bertoti, Giuliano A",
    title   = "DEEP LEARNING APLICADO NA CONVERSÃO DE LIBRAS EM TEXTO",
    journal = "Bol. T{\'e}cn. FATEC",
    year    = "2018",
    volume  = "46",
    pages   = "120"
}

@ARTICLE {fmenino2019b,
    author  = "Menino, Felipe Carlos and  Bertoti, Giuliano A",
    title   = "USO DE DEEP LEARNING PARA DESENVOLVER TECNOLOGIAS ASSISTIVAS DE BAIXO CUSTO",
    journal = "Bol. T{\'e}cn. FATEC",
    year    = "2018",
    volume  = "46",
    pages   = "144"
}

@ONLINE {dicioLibras2011,
    title = "Dicionário da Língua Brasileira de Sinais V3 - 2011",
    year  = "2011",
    url   = "http://www.acessibilidadebrasil.org.br/libras_3/"
}

@ONLINE {google2019,
    author = "Google",
    title  = "Google Trends",
    month  = "apr",
    year   = "2019",
    url    = "https://trends.google.com/trends/explore?date=2012-01-01%202019-01-01\&q=deep%20learning"
}

@article{ANDRIOLI2017,
abstract = {Tese de Doutorado},
author = {ANDRIOLI, MARY},
doi = {10.11606},
file = {:media/felipe/0AF2C7F6F2C7E453/MARY{\_}GRACE{\_}PEREIRA{\_}ANDRIOLI{\_}rev.pdf:pdf},
journal = {Teses.Usp.Br},
keywords = {Pol{\'{i}}tica Educacional. Tecnologia Assistiva. Defici},
number = {6},
pages = {278},
title = {{Desenvolvimento de recursos na {\'{a}}rea de Tecnologia Assistiva: desafios e possibilidades em Institutos Federais}},
url = {http://www.teses.usp.br/teses/disponiveis/48/48134/tde-31072017-160236/en.php},
year = {2017}
}

@ARTICLE {tve2016,
    author  = "Guilhermano, Livia and Ciocari, Antonio and Azevedo, Beto and Tavares, Rogerio",
    title   = "Tecnologias Assistivas",
    journal = "TVE RS",
    year    = "2016",
    url = "https://www.youtube.com/watch?v=-i9Av0gfzFI"
}

@ARTICLE {forbes2019,
    author  = "Press, Gil",
    title   = "7 Indicators Of The State-Of-Artificial Intelligence (AI), March 2019",
    journal = "Forbes",
    year    = "2019",
    url = "https://www.forbes.com/sites/gilpress/2019/04/03/7-indicators-of-the-state-of-artificial-intelligence-ai-march-2019/amp/?__twitter_impression=true"
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@article{Bersch2017,
author = {Bersch, Rita},
title = {{Introdu{\c{c}}{\~{a}}o {\`{A}} Tecnologia Assistiva}},
url = {www.assistiva.com.br},
year = {2017}
}

@article{pytorch2017,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@INPROCEEDINGS {handsfree2019,
    author    = "Ramos, OZ",
    title     = "Handsfree.js",
    booktitle = "A platform for browsing the web totaly handsfree using head tracking",
    year      = "2019",
    url = "https://glitch.com/edit/#!/handsfree-starter?path=README.md:1:0"
}

@article{Frid-Adar2018,
abstract = {Deep learning methods, and in particular convolutional neural networks (CNNs), have led to an enormous breakthrough in a wide range of computer vision tasks, primarily by using large-scale annotated datasets. However, obtaining such datasets in the medical domain remains a challenge. In this paper, we present methods for generating synthetic medical images using recently presented deep learning Generative Adversarial Networks (GANs). Furthermore, we show that generated medical images can be used for synthetic data augmentation, and improve the performance of CNN for medical image classification. Our novel method is demonstrated on a limited dataset of computed tomography (CT) images of 182 liver lesions (53 cysts, 64 metastases and 65 hemangiomas). We first exploit GAN architectures for synthesizing high quality liver lesion ROIs. Then we present a novel scheme for liver lesion classification using CNN. Finally, we train the CNN using classic data augmentation and our synthetic data augmentation and compare performance. In addition, we explore the quality of our synthesized examples using visualization and expert assessment. The classification performance using only classic data augmentation yielded 78.6{\%} sensitivity and 88.4{\%} specificity. By adding the synthetic data augmentation the results increased to 85.7{\%} sensitivity and 92.4{\%} specificity. We believe that this approach to synthetic data augmentation can generalize to other medical classification applications and thus support radiologists' efforts to improve diagnosis.},
archivePrefix = {arXiv},
arxivId = {1803.01229},
author = {Frid-Adar, Maayan and Diamant, Idit and Klang, Eyal and Amitai, Michal and Goldberger, Jacob and Greenspan, Hayit},
doi = {10.1016/j.neucom.2018.09.013},
eprint = {1803.01229},
file = {:home/felipe/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frid-Adar et al. - 2018 - GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Convolutional neural networks,Data augmentation,Deep learning,Generative adversarial network,Image synthesis,Lesion classification,Liver lesions},
pages = {321--331},
title = {{GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification}},
volume = {321},
year = {2018}
}

@ONLINE {pavlovskyvojtech2017,
    author = "Pavlovsky, Vojtech",
    title  = "Introduction To Convolutional Neural Networks",
    month  = "mar",
    year   = "2017",
    url    = "https://www.vaetas.cz/posts/intro-convolutional-neural-networks/"
}

@inproceedings{Park2018ECCV,
	author = {Park, Seonwook and Spurr, Adrian and Hilliges, Otmar},
	title = {Deep Pictorial Gaze Estimation},
	booktitle = {European Conference on Computer Vision (ECCV)},
	series = {ECCV '18},
	year = {2018},
	location = {Munich, Germany},
}

@article{Griffin,
abstract = {Eye tracking is an integral part of many VR and AR sys- tems. Common eye tracking algorithms use infrared LEDs shown onto the eye, then compute the relative distance of that light to the pupil of the eye as a means to determine eye movement. We suggest that using a fast classification method, such as CNNs, on a relatively dense dataset and using interpolation methods could give similar speed and accuracy},
author = {Griffin, Jonathan and Ramirez, Andrea},
title = {{Convolutional Neural Networks for Eye Tracking Algorithm}},
year = {2018}
}

@article{Lemley2018,
abstract = {Accurate and efficient eye gaze estimation is important for emerging consumer electronic systems such as driver monitoring systems and novel user interfaces. Such systems are required to operate reliably in difficult, unconstrained environments with low power consumption and at minimal cost. In this paper a new hardware friendly, convolutional neural network model with minimal computational requirements is introduced and assessed for efficient appearance-based gaze estimation. The model is tested and compared against existing appearance based CNN approaches, achieving better eye gaze accuracy with significantly fewer computational requirements. A brief updated literature review is also provided.},
archivePrefix = {arXiv},
arxivId = {1806.10890},
author = {Lemley, Joseph and Kar, Anuradha and Drimbarean, Alexandru and Corcoran, Peter},
eprint = {1806.10890},
file = {:C$\backslash$:/Users/User/Documents/livros/1806.10890.pdf:pdf},
pages = {1--9},
title = {{Efficient CNN Implementation for Eye-Gaze Estimation on Low-Power/Low-Quality Consumer Imaging Systems}},
url = {http://arxiv.org/abs/1806.10890},
year = {2018}
}

@book{murphy2012,
  title={Machine Learning: A Probabilistic Perspective. Adaptive Computation and Machine Learning},
  author={Murphy, Kevin P},
  year={2012},
  publisher={MIT press}
}

@BOOK {gibsonadampattersonjosh2017,
    author    = "Gibson, Adam and Patterson, Josh",
    title     = "Deep Learning",
    publisher = "O'Reilly Media, Inc.",
    year      = "2017"
}

@ARTICLE {shepherdgordonm1990,
    author    = "Shepherd, Gordon M",
    title     = "The Synaptic Organization of the Brain",
    publisher = "Oxford University Press",
    year      = "1990"
}

@misc{mnielsen2018,
  author = "Nielsen, Michael",
  title = "Neural Networks and Deep Learning",
  url = "http://neuralnetworksanddeeplearning.com/chap6.html",
  year = "2018"
}

@article{nair2010,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
  year={2010}
}

@misc{Peternelli2003,
author = {Peternelli, Luiz Alexandre},
file = {:media/felipe/0AF2C7F6F2C7E453/Users/User/Documents/livros/CAPITULO9.pdf:pdf},
title = {{Regress{\~{a}}o linear e correla{\c{c}}{\~{a}}o}},
url = {http://www.dpi.ufv.br/{~}peternelli/inf162.www.16032004/materiais/CAPITULO9.pdf},
year = {2003}
}

@BOOK {mannprems2006,
    author    = "Mann, Prem s",
    title     = "Introdução à Estatística",
    publisher = "LTC",
    year      = "2006",
    edition   = "fifth"
}

@MISC {andrewngcourse,
    author = "NG, Andrew and Katanforoosh, Kian and Mourri, Younes Bensouda",
    title  = "Neural Networks and Deep Learning",
    year   = "2016"
}

@ONLINE {tonollijoseberschrita2017,
    author = "Tonolli, Jos\'e and Bersch, Rita",
    title  = "O que é Tecnologia Assistiva?",
    year   = "2017",
    url    = "http://www.assistiva.com.br/tassistiva.html"
}

@book{introDataMining2009,
  Author = {Tan, Pang-Ning and Steinbach, Michel and Kumar, Vipin},
  Title = {Introdução ao Data Mining. Mineração de Dados (Em Portuguese do Brasil)},
  Publisher = {Ciência Moderna},
  Year = {2009},
  ISBN = {8573937610}
}

@article{DeOliveira2011,
author = {{Oliveira}, F{\'{a}}tima In{\^{e}}s Wolf De and Cardoso, Luciana Santana},
doi = {10.5216/rp.v22i1.21218},
issn = {2236-0514},
journal = {Polyphon{\'{i}}a},
number = {1},
title = {{Recursos de tecnologia assistiva para alunas com surdez: sugest{\~{o}}es compartilhadas por uma bolsista Pibid}},
volume = {22},
year = {2011}
}

@book{paulovazdecarvalho2019,
 Author = {Paulo Vaz de Carvalho},
 title = {Breve História dos Surdos no Mundo (Portuguese Edition)},
 description = {Breve História dos Surdos no Mundo (Portuguese Edition) (Book, 2007)},
 interhash = {fa54e71bcad63d7d0567a2d9caf9c530},
 intrahash = {046782db0b1713e956bb53e95cf23587},
 year = {2007},
 isbn = {9899525413},
 url = {https://www.xarg.org/ref/a/B01JLVZQUW/}
}

@ONLINE {markewiczpaulamaria2017,
    author = "Markewicz, Paula Maria",
    title  = "Cumprimentos em Libras Fáceis para você Fazer – Com Vídeos",
    year   = "2017",
    url    = "http://www.cursodelibras.org/artigos/cumprimentos-em-libras/"
}


% @Comment{jabref-meta: databaseType:bibtex;}
